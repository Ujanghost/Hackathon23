# -*- coding: utf-8 -*-
"""Jugaad Q-4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N9l2gKwo-z-vj_qCpK5rtDoCM0AZ2Y6E
"""

import pandas as pd



data=pd.read_csv("encoded.csv")

data

import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st


# Set the aesthetic style of the plots
sns.set_style('whitegrid')

# Plot distributions of 'Dalc', 'Walc', and 'G3'
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Daily alcohol consumption
sns.histplot(data['Dalc'], bins=5, kde=False, ax=axes[0])
axes[0].set_title('Distribution of Daily Alcohol Consumption')

# Weekly alcohol consumption
sns.histplot(data['Walc'], bins=5, kde=False, ax=axes[1])
axes[1].set_title('Distribution of Weekly Alcohol Consumption')

# Final grade
sns.histplot(data['G3'], bins=range(0, 21), kde=False, ax=axes[2])
axes[2].set_title('Distribution of Final Grade (G3)')

plt.tight_layout()
plt.show()

"""Random Forest"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder

# Assuming your DataFrame is named 'data'
# Replace 'data.csv' with your actual data file if needed
data = pd.read_csv('encoded.csv')

# Selecting features related to alcohol consumption and other relevant features
alcohol_features = ['Dalc', 'Walc', 'health', 'absences', 'G1', 'G2', 'goout']
other_features = ['sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian',
                   'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',
                   'higher', 'internet', 'romantic', 'famrel', 'freetime']

# Extracting the relevant features and target variable
X = data[alcohol_features]
y = data['G3']

# # Convert categorical columns to numerical using Label Encoding
# label_encoder = LabelEncoder()
# categorical_columns = ['sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup',
#                         'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']
# for column in categorical_columns:
#     X[column] = label_encoder.fit_transform(X[column])

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a RandomForestRegressor model
model = RandomForestRegressor(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Make predictions on the test set
predictions = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, predictions)
r_squared = r2_score(y_test, predictions)

st.write(f'Mean Squared Error: {mse}')
st.write(f'R-squared: {r_squared}')

"""Gradient Boosting"""

from sklearn.ensemble import GradientBoostingRegressor

# Initialize the GradientBoostingRegressor
gbr = GradientBoostingRegressor(n_estimators=100, random_state=42)

# Fit the model
gbr.fit(X_train, y_train)

# Predict on the test set
y_pred = gbr.predict(X_test)

# Calculate the root mean squared error
# rmse = sqrt(mean_squared_error(y_test, y_pred))

# # Output the RMSE
# st.write('Root Mean Squared Error:', rmse)

r_squared = r2_score(y_test, y_pred)
st.write(r_squared)

"""XG-Boost Regressor"""

from xgboost import XGBRegressor # Training the XGBoost Regressor
model = XGBRegressor(n_estimators=100, random_state=42)  # You can adjust the parameters as needed
model.fit(X_train, y_train)

# Make predictions
predictions = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, predictions)
st.write(f'Mean Squared Error: {mse}')

r_squared = r2_score(y_test, predictions)
st.write(r_squared)

# # Extract feature importances for 'Dalc' and 'Walc'
# alcohol_importances = features_df[features_df['Feature'].isin(['Dalc', 'Walc'])]
# st.write(alcohol_importances)

# Calculate the correlation matrix including 'Dalc', 'Walc', and 'G3'
correlation_matrix = data[['Dalc', 'Walc', 'G3']].corr()
correlation_matrix

"""The correlation analysis reveals the following relationships:
There is a moderate positive correlation between daily and weekly alcohol consumption ('Dalc' and 'Walc').
Both 'Dalc' and 'Walc' have a negative correlation with the final grade ('G3'), suggesting that as alcohol consumption increases, the final grade tends to decrease.
Next, I will create visualizations to better illustrate these relationships.
"""

# Set up the matplotlib figure
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Scatter plot for 'Dalc' vs 'G3'
sns.scatterplot(x='Dalc', y='G3', data=data, ax=axes[0])
axes[0].set_title('Daily Alcohol Consumption vs Final Grade')

# Scatter plot for 'Walc' vs 'G3'
sns.scatterplot(x='Walc', y='G3', data=data, ax=axes[1])
axes[1].set_title('Weekly Alcohol Consumption vs Final Grade')

plt.tight_layout()
plt.show()

"""The scatter plots illustrate the relationships between alcohol consumption and final grades:
The first plot shows the relationship between daily alcohol consumption ('Dalc') and final grade ('G3').
The second plot shows the relationship between weekly alcohol consumption ('Walc') and final grade ('G3').
In both cases, there is no clear trend indicating a strong relationship, which aligns with the relatively low negative correlation values and feature importances observed earlier. This suggests that while there is a slight tendency for grades to decrease with higher alcohol consumption, other factors are more strongly predictive of academic performance.
"""

